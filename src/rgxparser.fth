\ LexGen regex parser

\ Generated by Grace 2.0.1
\ See http://www.qlikz.org/forth/grace/grace.html

\ ------------------------------------------------------------------------------
\ LexGen - scanner module
\ Copyright (C) Gerry Jackson 2011, 2018

\ This software is covered by the MIT software license, a copy of which should
\ have accompanied this file. If not see https://opensource.org/licenses/MIT

\ Uses a state transition table generated by LexGen
\ Simplified version of a file scanner

\ Derived from the Regex scanner

[defined] [rgx-dev] [if] .( Loading rgxscan.fth ...) cr [then]

\ ---[ Unique scanner id ]------------------------------------------------------

create lexgen-scanner-id-string  \ For use by other programs

\ ---[ get-char from a string ]------------------------------------------------

2variable regex-source     \ Current line of regular expression being compiled  
2variable regex-str        \ Position in the current line
variable curr-char         \ Last character read

: set-regex  ( caddr u -- )  2dup regex-source 2! regex-str 2! ;

: get-char  ( -- ch | -1 )    \ -1 is end of string
   regex-str 2@ over swap ?dup      ( -- caddr caddr [ u u | 0 ] )
   if
      1 /string regex-str 2! c@
      dup curr-char ! exit          ( -- ch )
   then
   =                                ( -- -1 )
;

: get-pos  ( -- caddr )  regex-str cell+ @ ;

: reset-pos  ( caddr -- )
   regex-str 2@ >r over - r> +
   over 1 chars - c@ curr-char !
   regex-str 2!
;

: get-string  ( -- caddr u )  postpone regex-str postpone 2@ ; immediate

: scan-to-char  ( ch -- caddr u caddr2 u2 )
   >r regex-str 2@ 2dup
   begin
      dup
   while
      over c@ r@ <>
   while
      1 /string
   repeat then
   r> drop
;

: parse-to-char  ( ch -- caddr u )
   scan-to-char tuck regex-str 2! -
;

: parse-past-char  ( ch -- caddr u )
   parse-to-char
   regex-str 2@ dup if 1 /string regex-str 2! else 2drop then
;

\ ---[ Temporarily needed ]-----------------------------------------------------

: open-source   ( -- )  ;
: close-source  ( -- )  ;

\ ---[ Save and restore scanner state ]-----------------------------------------

object class
   2 cells var sav-rgxstr
   2 cells var sav-rgxsrc
end-class ScannerState

: save-scanner  ( obj -- )
   >r regex-str 2@ r@ sav-rgxstr 2!
   regex-source 2@ r> sav-rgxsrc 2!
;

: restore-scanner  ( obj -- )
   dup sav-rgxstr 2@ regex-str 2!
   sav-rgxsrc 2@ regex-source 2!
;

-1 value eof-tok

\ ---[ Access lex arrays ]------------------------------------------------------

1 cells constant 1cell
2 cells constant 2cells
3 cells constant 3cells

: BaseDefault  ( index -- ad )
   3cells * BaseDefaultData +
;

: CheckNext    ( index -- ad )
   2cells * CheckNextData +
;

\ These definitions are for readability in the scanner

: lexBase ; immediate         \ Compiles nothing
: lexDefault postpone cell+ ; immediate
: lexToken postpone cell+ postpone cell+ ; immediate 
: lexCheck ; immediate
: lexNext postpone cell+ ; immediate

\ ---[ Lex arrays, index to abs addresses ]-------------------------------------
\ Conversion of lex array data to absolute addresses. Using absolute addresses
\ is faster than using the array data to index the arrays. An alternative is
\ to replace the , in the LexTables data with a word that does the conversion
\ as the file is read

: ?invalid  ( ad1 -- ad2 | 0 )   \ 0 if contents of ad1 negative
   @ dup 0<
   if
      drop 0
   else
      BaseDefault
   then
;

: >addresses
   BaseDefaultData #states 3cells * over + swap
   ?do
      i lexBase @ CheckNext i lexBase !
      i lexDefault ?invalid i lexDefault !
      3cells
   +loop
   CheckNextData maxCheck 2cells * over + swap
   ?do
      i lexCheck ?invalid i lexCheck !
      i lexNext  ?invalid i lexNext !
      2cells
   +loop
   maxcheck CheckNext to maxCheck
;

>addresses    \ Do the conversion to absolute addresses

\ ---[ Lexical scanning ]-------------------------------------------------------

\ nextState returns 0 if there is no valid next state

\ state and state2 are addesses, ch' is a character converted to cells
\ by the caller

: next-state    ( state ch' -- state2 )
   tuck over 2>r              ( -- ch' state )  ( R: -- ch' state )
   tuck lexBase @ +           ( -- state ad1 )
   dup CheckNextData maxCheck
   within                     ( -- state ad1 f ) \ f = 0 is out of range
   if
      dup lexCheck @ r@ =     ( -- state ad1 f )
      if
         nip lexNext @        ( -- state2 )
         2r> 2drop exit
      then
   then
   r> 2drop lexDefault @      ( -- state3 )  ( R: -- ch )
   r> over                    ( -- state3 ch f )   \ Should this be 0>= ??
   if recurse exit then       ( -- state4 )
   drop                       ( -- 0 )
;

\ nextToken returns 0 for invalid token else valid token. In regex this
\ is treated as a single character to be matched.
\ Note when a state has a valid token, this is remembered and we carry on
\ until we can get no further. This allows a longer lexeme to be recognised
\ and backtracking (within the line) if there is none such.
\ This scanner is a modified version of the library scanner so that it can
\ handle tokens in both a regular expression and in a character class
\ using the same state transition tables. This is done by passing a leading
\ character into next-token. This character is used instead of reading the
\ first character from the regular expression.

: next-token    ( ch -- caddr u token )
   get-pos swap regex-str @ 0=      ( -- caddr1 ch f )
   if eof-tok exit then             ( -- x x token )
   2cells * >r dup char+            ( -- caddr1 caddr2 )
   0 BaseDefaultData r>             ( -- caddr1 caddr2 tok state ch' )
   begin
      next-state dup                ( -- caddr1 caddr2 tok state2 state2)
   while
      dup lexToken @ 0>             ( -- caddr1 caddr2 tok state2 f )
      if
         >r 2drop get-pos           ( -- caddr1 caddr3 )
         r@ lexToken @ r>           ( -- caddr1 caddr3 tok2 state2 )
      then
      get-char 2cells *
   repeat
   drop >r 2dup reset-pos - r>      ( -- caddr1 u token )
;

\ -----------------------------------------------------------------------------
\ To read in tokens as used by LexGen

\ Defines a token that returns a unique value

variable tokenval 1 tokenval !

: token ( -- ) ( use: token name ) ( name: -- n )
   tokenval @ constant
   1 tokenval +!
;

: token>  ( -- )  token ;

\ ------------------------------------------------------------------------------

[defined] [rgx-dev] [if] .( regexscan.fth loaded ) .s [then]


1 constant end_of_regex
2 constant white_space
3 constant '(?end)'
[defined] lexgen-scanner-id-string [if]
   1 to eof-tok
[then]
0 constant [skip-whitespace]
32 constant bits/cell
defer lexer
\ ---[ Interface to the scanner ]-----------------------------------------------

\ ---[ Shared variables ]-------------------------------------------------------

variable sym
2variable symname
\ 2variable regex-source

\ ---[ Fetch next token ]-------------------------------------------------------
 
\ Characters to start all tokens
char _ constant re-token   \ For regex tokens

variable regex-mode        \ Holds the constant above

end_of_regex constant end-of-line

: -leading  ( caddr u -- caddr' u' )   \ Skip leading spaces
   begin over c@ bl <= while 1 /string repeat
;

: get-token ( -- caddr u tok )
      regex-mode @ next-token
\ cr dup . >r 2dup type r>
;

\ ---[ Interface to the regex parser ]------------------------------------------

\ Values to be loaded by the parser

0 value first-set

\ This version for multi-cell sets and should be safe to use on both little
\ and big endian processors

s" ADDRESS-UNIT-BITS" environment? 0= [if] 8 [then] \ May need adjustment
constant bits/au   \ number of set bits per address unit

: testsym?  ( set-index -- f )
   first-set +                         ( -- ad )
   sym @ bits/au /mod chars rot + c@   ( -- bit vec )
   1 rot lshift and                    ( -- f )
;

: test-token  ( n -- f )  sym @ = ;

: report-error  ( -- )
   regex-source 2@                  ( -- caddr u )
   cr over swap type cr             ( -- caddr )
   regex-str 2@ drop                ( -- caddr caddr2 )
   swap - spaces ." ^ "
   -1 abort" syntax error"
;

: nextsym  ( -- )  get-token sym ! symname 2! ;

: ?nextsym  ( f -- )
   0= if report-error then
   nextsym
;


\ ------------------------------------------------------------------------------
\ LexGen - the regular expression actions module

\ Copyright (C) Gerry Jackson 2011, 2018

\ This software is covered by the MIT software license, a copy of which should
\ have accompanied this file. If not see https://opensource.org/licenses/MIT

[defined] [-dev-] [if] .( Loading rgxactions.fth ...) cr [then]


\ ---[ Actions called by the parser ]-------------------------------------------

: control-char  ( -- u )   \ 0 <= u < 32
   get-char dup 0<                  ( -- ch f )
   if ." Character expected after \c" report-error then
   bl mod
;

base @ decimal
 0 constant ^nul   9 constant ^ht   10 constant ^lf   13 constant ^cr
base !

: >num  ( u1 -- u2 )
   base @ >r base !
   0 0 [char] } parse-to-char    ( -- ud caddr u )
   >number 2drop drop            ( -- u2 )
   r> base !
;

base @ decimal
: dec-num  ( -- u )  10 >num ;   \ For \d{...}
: hex-num  ( -- u )  16 >num ;   \ For \x{...}
base !

: set-allchars  ( set -- set' )
   dup get-maxmember 0           ( -- set u 0 )
   do i [+] loop
;

variable first-char  \ For first char in a character class range

: ((char>set))  ( set f ch -- set f )
   >r tuck if r> [-] else r> [+] then
   swap
;

: (char>set)  ( set f ch -- set f )
   caseInsens
   if dup >r >lower ((char>set)) r> >upper then
   ((char>set))
;

: char>set  ( set f ch -- set f )
   dup first-char ! (char>set)
;

: range>set  ( set f ch -- set f )
   first-char @ 2dup <
   if ." Error in character range" report-error then
   swap 1+ swap
   do i (char>set) loop
;

wordlist constant regex-names

: get-regex  ( -- tree )
   [char] } parse-to-char        ( -- caddr u )
   regex-names search-wordlist   ( -- 0 | xt +/-1 )
   0= if ." Regular expression name not found" report-error then
   execute
;

\ ---[ To parse and compile a regular expression ]------------------------------

: (regex)  ( -- tree )
   source >in @ /string -leading -trailing
   re-token regex-mode !
   2dup regex-source 2! set-regex
   lexer
   source nip regex-str @ - >in !
;

: regex  ( "spaces<name>" --  )  \ name execute ( -- tree )
   get-current regex-names set-current
   create set-current here >r 0 , 0 , (regex) r> !
   do-regexp            ( -- tree )
;

\ Associate token constants with symbols, syntax:
\    "token" ==> <regular expression>

: ==>  ( tree? n "spaces"<regex>"spaces" -- tree2 )
   (regex) yields 
;

\ : ==>$  ( tree? n "spaces"<string>"spaces" -- tree2 )
\   symbol
\ ;

\ ------------------------------------------------------------------------------
[defined] [-dev-] [if] .( rgxactions.fth loaded ) .s [then]
\ ------------------------------------------------------------------------------


: metachar symname 2@ drop char+ c@ 0 testsym? if 17 test-token if 
nextsym else 8 testsym? if 18 test-token if nextsym else 19
test-token ?nextsym then else 20 test-token if nextsym else 21
test-token ?nextsym then then then else 16 testsym? if 24 testsym? if 22
test-token if nextsym else 23 test-token ?nextsym then else 24
test-token if nextsym else 25 test-token ?nextsym then then else
32 testsym? if 26 test-token if nextsym else 27 test-token
?nextsym then else 28 test-token if nextsym else 29 test-token
?nextsym then then then then ; : escapedchar 40 testsym? if 30 test-token if
^nul nextsym else 48 testsym? if 31 test-token if ^ht 
nextsym else ^lf 32 test-token ?nextsym then else 33 test-token if
^cr nextsym else bl 34 test-token ?nextsym then then then else 35
test-token if control-char nextsym else 36 test-token if dec-num
nextsym else hex-num 37 test-token ?nextsym then 16 test-token
?nextsym then then ; : onechar 0 test-token if symname 2@ drop c@ 
nextsym else 56 testsym? if metachar else escapedchar then then ; : charclass
CharSet new 10 test-token if 0 nextsym else set-allchars -1 11
test-token ?nextsym then begin onechar char>set 12 test-token if 
nextsym onechar range>set then 64 testsym? 0= until drop 13 test-token ?nextsym ;
defer subregexpr

: term 72 testsym? if 64 testsym? if onechar new-charnode else charclass
LeafCharSetNode new then else 8 test-token if nextsym subregexpr 9
test-token ?nextsym else get-regex 15 test-token ?nextsym 16 test-token ?nextsym
then then ; : quanterm term 80 testsym? if 5 test-token if <*> 
nextsym else 6 test-token if <+> nextsym else <?> 7 test-token
?nextsym then then then ; : concat quanterm begin 88 testsym? while quanterm <.>
repeat ; :noname concat begin 4 test-token while nextsym concat
<|> repeat ; is subregexpr : regexpression subregexpr 1 test-token if 
nextsym else 3 test-token ?nextsym then ;
 : ~ 0 0 parse-name >number 2drop drop 4 0 do dup c, 8 rshift loop drop ;
here to first-set base @ decimal 36 base ! ~ 2F37K ~ 0 ~ GUTC ~ 0 ~ 11GH6O ~ 0
~ 7HP1C ~ 0 ~ 3BV4LC ~ 0 ~ 1H9U1HC ~ 7 ~ ZIK0ZK ~ 1 ~ HR77CW ~ 0 ~ 1Z118U9 ~ 1R
~ 1Z11B7L ~ 1R ~ 68 ~ 0 ~ 1Z120OX ~ 1R base !
:noname open-source nextsym regexpression close-source ; is lexer

